# 从外部数据库同步文件到文件存储HDFS

本文描述了如何从零开始创建从外部数据库同步文件到文件存储HDFS的手动调度的任务。


## 开始前准备<beforestart>

你必须已完成外部数据库的数据源连接，且外部数据库中已存储待同步的文件。更多信息，参考[外部源连接](../data_source/index)。


## 步骤1：创建数据集成任务<create_job>

1. 在EnOS控制面板中选择 **数据集成**。

2. 点击目录树上方的 **+**，新建数据集成任务。

3. 在 **新建数据集成任务** 窗口中，完成数据集成任务的基本设置。

   - 方式：选择 **新建** 以从零开始创建集成任务。如果选择 **导入任务配置**，参考[基于已有任务创建新的集成任务](importing_existing_config)。
   - 名称：输入数据集成任务的名称。
   - 同步类型：选择 **文件同步**。
   - 调度类型：选择 **手动调度**。
   - 描述：输入对数据集成任务的描述性信息。
   - 选择目录：选择保存数据集成任务的目录。

4. 单击 **确定** 完成创建。


## 步骤2： 选择数据源<select_source>

选择同步文件的数据源，同步到文件存储HDFS，需要完成如下配置：

1. 在 **数据源类型** 中，选择文件数据源。目前支持Azure BLOB数据库。
2. 在 **数据源** 中，选择在外部源连接中已经注册的数据源。可点击**新增数据源**，打开**外部源连接**页面，注册新的数据源。
3. 在 **目录或文件名** 中，输入待同步的文件目录或文件名。目录或文件名支持输入通配符、系统变量及自定义变量。若填写目录，目录必须以“/”结尾。
4. 点击 **下一步**，选择同步文件目标。


## 步骤3：选择目标<select_target>

目前文件同步目标只支持文件存储HDFS，需要完成如下配置：

1. 在 **数据源类型** 中，选择HDFS。

2. 在 **目录** 中，输入存储同步文件的子目录。子目录必须以“/”结尾。如果不输入子目录，则文件或目录结构默认同步到根目录下面。

3. 选择 **文件写入规则**，即出现同名文件时，选择覆盖或不覆盖同名文件：

   - 同名文件覆盖：在文件同步过程中，如果在相同目录下遇到同名文件，后到达文件会自动覆盖先到达的文件。
   - 同名文件不覆盖：在文件同步过程中，如果在相同目录下遇到同名文件，则任务终止，log中会记录同名文件的信息。任务终止后，已同步至HDFS的文件不会被自动清理。

4. 点击 **下一步**。

## 步骤4：配置并发数

选择要建立的并发连接数，然后点击 **下一步** 。

如设置高并发数，数据库会承受更大的负载，当总传输速率固定时，单个连接的速率会变小。


## 步骤5：预览并保存配置<preview_job>

预览任务配置，如需再编辑，点击**修改**跳转到对应步骤。然后点击 **完成** 保存配置。完整的任务配置信息如下图所示：

.. image:: media/sync_file.png


## 后续操作<followup>

点击 **预跑** 并选择触发时间，测试文件同步任务。

实例将在运行集成任务后产生。接着，你可在 **数据运维** 页面跟踪有关实例的详细信息。更多信息，参考[数据运维](../task_monitor/index)。

从源数据库同步文件后，你可以设置其它数据或文件处理任务。更多信息，参考[数据开发套件](../data_ide/dataide_overview)。
